<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Kafka | Shang Liang Liang's Blog</title><meta name="description" content="Kafka1. Kafka 有⼏种数据保留的策略?1.按照过期时间保留。2.按照存储的消息⼤小保留。 2. 请说明什么是Apache Kafka?Apach Kafka 一种发布订阅消息系统。Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理&#x3D;&#x3D;流式数据&#x3D;&#x3D;。 2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？Kafka是一个流处理平台。它可以"><meta name="keywords" content="Kafka"><meta name="author" content="Shang Liang Liang"><meta name="copyright" content="Shang Liang Liang"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/logo.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://hm.baidu.com"/><link rel="dns-prefetch" href="https://hm.baidu.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Kafka"><meta name="twitter:description" content="Kafka1. Kafka 有⼏种数据保留的策略?1.按照过期时间保留。2.按照存储的消息⼤小保留。 2. 请说明什么是Apache Kafka?Apach Kafka 一种发布订阅消息系统。Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理&#x3D;&#x3D;流式数据&#x3D;&#x3D;。 2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？Kafka是一个流处理平台。它可以"><meta name="twitter:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gwvtnero3ij31hn0u00ts.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Kafka"><meta property="og:url" content="http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka/"><meta property="og:site_name" content="Shang Liang Liang's Blog"><meta property="og:description" content="Kafka1. Kafka 有⼏种数据保留的策略?1.按照过期时间保留。2.按照存储的消息⼤小保留。 2. 请说明什么是Apache Kafka?Apach Kafka 一种发布订阅消息系统。Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理&#x3D;&#x3D;流式数据&#x3D;&#x3D;。 2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？Kafka是一个流处理平台。它可以"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gwvtnero3ij31hn0u00ts.jpg"><meta property="article:published_time" content="2021-11-18T02:39:39.000Z"><meta property="article:modified_time" content="2022-02-21T01:12:43.316Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka/"><link rel="prev" title="开窗函数" href="http://yoursite.com/2021/11/29/%E9%A1%B9%E7%9B%AE%E8%B8%A9%E5%9D%91/%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0/"><link rel="next" title="Kafka数据可靠性和一致性" href="http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%92%8C%E4%B8%80%E8%87%B4%E6%80%A7/"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?16c6948b730158e8efcea17a55c7ca6d";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: Shang Liang Liang","link":"链接: ","source":"来源: Shang Liang Liang's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: {"text":"求知,好学","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: false,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Shang Liang Liang's Blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">57</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Kafka-有⼏种数据保留的策略"><span class="toc-text">1. Kafka 有⼏种数据保留的策略?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-请说明什么是Apache-Kafka"><span class="toc-text">2. 请说明什么是Apache Kafka?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-0-Apache-Kafka是分布式流处理平台吗？如果是，你能用它做什么？"><span class="toc-text">2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-Kafka的优点有那些？"><span class="toc-text">&#x3D;&#x3D;2.1.1 Kafka的优点有那些？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-Kafka的缺点有哪些？"><span class="toc-text">2.1.2 Kafka的缺点有哪些？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-为什么要使用-Kafka？为什么要使用消息队列？"><span class="toc-text">2.2 为什么要使用 Kafka？为什么要使用消息队列？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Kafka中有哪几个组件"><span class="toc-text">3. Kafka中有哪几个组件?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-什么是消费者组？"><span class="toc-text">3.1 什么是消费者组？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-Leader和Follower的概念是什么？"><span class="toc-text">3.2 Leader和Follower的概念是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-Kafka-Follower如何与Leader同步数据"><span class="toc-text">3.3 Kafka Follower如何与Leader同步数据?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-数据传输的事物定义有哪三种"><span class="toc-text">4. 数据传输的事物定义有哪三种?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-Kafka-判断一个节点是否还活着有那两个条件"><span class="toc-text">&#x3D;&#x3D;5. Kafka 判断一个节点是否还活着有那两个条件?&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-Kafka中的-zookeeper-起到什么作用？可以不用zookeeper吗？"><span class="toc-text">&#x3D;&#x3D;5.1 Kafka中的 zookeeper 起到什么作用？可以不用zookeeper吗？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-producer-是否直接将数据发送到-broker-的-leader-主节点"><span class="toc-text">6. producer 是否直接将数据发送到 broker 的 leader(主节点)?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-Kafa-consumer-是否可以消费指定分区消息"><span class="toc-text">7. Kafa consumer 是否可以消费指定分区消息?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-Kafka-分区的目的？"><span class="toc-text">7.1 Kafka 分区的目的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-Kafka-消息是采用-Pull-模式，还是-Push-模式"><span class="toc-text">&#x3D;&#x3D;8. Kafka 消息是采用 Pull 模式，还是 Push 模式?&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-Kafka-存储在硬盘上的消息格式是什么"><span class="toc-text">&#x3D;&#x3D;9. Kafka 存储在硬盘上的消息格式是什么?&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-1-Kafka可以接收的消息最大为多少？"><span class="toc-text">9.1 Kafka可以接收的消息最大为多少？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-Kafka-高效文件存储设计特点"><span class="toc-text">10. Kafka 高效文件存储设计特点:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-Kafka-与传统消息系统之间有三个关键区别"><span class="toc-text">11. Kafka 与传统消息系统之间有三个关键区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-Kafka-创建-Topic-时如何将分区放置到不同的-Broker-中"><span class="toc-text">12. Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-Kafka-新建的分区会在哪个目录下创建"><span class="toc-text">13. Kafka 新建的分区会在哪个目录下创建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-partition-的数据如何保存到硬盘"><span class="toc-text">14. partition 的数据如何保存到硬盘</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-kafka-的-ack-机制"><span class="toc-text">&#x3D;&#x3D;15. kafka 的 ack 机制&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-Kafka-的消费者如何消费数据"><span class="toc-text">16. Kafka 的消费者如何消费数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-1-偏移的作用是什么？"><span class="toc-text">16.1 偏移的作用是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-消费者负载均衡策略"><span class="toc-text">17. 消费者负载均衡策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#18-数据有序"><span class="toc-text">18. 数据有序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#19-kafaka-生产数据时数据的分组策略"><span class="toc-text">19.kafaka 生产数据时数据的分组策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20-Kafka系统工具有哪些类型？"><span class="toc-text">20. Kafka系统工具有哪些类型？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#20-1-监控-Kafka-的框架都有哪些"><span class="toc-text">20.1 监控 Kafka 的框架都有哪些?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#21-Kafka-是如何实现高吞吐率的？"><span class="toc-text">&#x3D;&#x3D;21 Kafka 是如何实现高吞吐率的？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-Kafka中的-ISR、AR-又代表什么？ISR-的伸缩又指什么？"><span class="toc-text">22. Kafka中的 ISR、AR 又代表什么？ISR 的伸缩又指什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-1-什么情况下一个-Broker-会从ISR中踢出去"><span class="toc-text">22.1 什么情况下一个 Broker 会从ISR中踢出去?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-2-如果-Leader-Crash-时，ISR为空怎么办"><span class="toc-text">22.2 如果 Leader Crash 时，ISR为空怎么办</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#22-3-副本长时间不在ISR中，这意味着什么？"><span class="toc-text">22.3 副本长时间不在ISR中，这意味着什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#23-Kafka-Producer如何优化写入速度"><span class="toc-text">23. Kafka Producer如何优化写入速度?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#24-Kafka-Unclean-配置代表什么？会对-spark-streaming-消费有什么影响？"><span class="toc-text">24. Kafka Unclean 配置代表什么？会对 spark streaming 消费有什么影响？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#25-Kafka-中-Consumer-Group-是什么概念？"><span class="toc-text">&#x3D;&#x3D;25. Kafka 中 Consumer Group 是什么概念？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#26-Kafka-中的消息是否会丢失和重复消费？"><span class="toc-text">&#x3D;&#x3D;26. Kafka 中的消息是否会丢失和重复消费？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#27-为什么Kafka不支持读写分离？"><span class="toc-text">&#x3D;&#x3D;27. 为什么Kafka不支持读写分离？&#x3D;&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#28-Kafka-中是怎么体现消息顺序性的？"><span class="toc-text">28. Kafka 中是怎么体现消息顺序性的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#29-Kafka-如何实现延迟队列"><span class="toc-text">29. Kafka 如何实现延迟队列?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#30-Kafka中的HW、LEO、LSO、LW等分别代表什么？"><span class="toc-text">30. Kafka中的HW、LEO、LSO、LW等分别代表什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#31-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"><span class="toc-text">31. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#32-优先副本是什么？它有什么特殊的作用？"><span class="toc-text">32. 优先副本是什么？它有什么特殊的作用？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#33-如果我指定了一个offset，Kafka怎么查找到对应的消息？"><span class="toc-text">33.如果我指定了一个offset，Kafka怎么查找到对应的消息？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#34-谈一谈-Kafka-的再均衡"><span class="toc-text">34. 谈一谈 Kafka 的再均衡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#35-如何调优-Kafka"><span class="toc-text">&#x3D;&#x3D;35. 如何调优 Kafka?&#x3D;&#x3D;</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="color"></div><div class="post-bg" id="nav" style="background-image: url(https://tva1.sinaimg.cn/large/008i3skNly1gwvtnero3ij31hn0u00ts.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Shang Liang Liang's Blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Kafka</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-11-18 10:39:39"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2021-11-18</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2022-02-21 09:12:43"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2022-02-21</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Kafka/">Kafka</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">6.6k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 21 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h4 id="1-Kafka-有⼏种数据保留的策略"><a href="#1-Kafka-有⼏种数据保留的策略" class="headerlink" title="1. Kafka 有⼏种数据保留的策略?"></a>1. Kafka 有⼏种数据保留的策略?</h4><p>1.按照过期时间保留。2.按照存储的消息⼤小保留。</p>
<h4 id="2-请说明什么是Apache-Kafka"><a href="#2-请说明什么是Apache-Kafka" class="headerlink" title="2. 请说明什么是Apache Kafka?"></a>2. <strong>请说明什么是Apache Kafka?</strong></h4><p>Apach Kafka 一种发布订阅消息系统。Kafka是一个<strong>分布式</strong>，<strong>可划分的</strong>，<strong>冗余备份</strong>的持久性的日志服务，它主要用于处理<strong>==流式数据==</strong>。</p>
<h4 id="2-0-Apache-Kafka是分布式流处理平台吗？如果是，你能用它做什么？"><a href="#2-0-Apache-Kafka是分布式流处理平台吗？如果是，你能用它做什么？" class="headerlink" title="2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？"></a>2.0 Apache Kafka是分布式流处理平台吗？如果是，你能用它做什么？</h4><p>Kafka是一个流处理平台。它可以完成以下工作：</p>
<ol>
<li>轻松推送记录。2. 可以存储大量记录，而不会出现任何存储问题。3. 它还可以在记录进入时对其进行处理。</li>
</ol>
<h4 id="2-1-1-Kafka的优点有那些？"><a href="#2-1-1-Kafka的优点有那些？" class="headerlink" title="==2.1.1 Kafka的优点有那些？=="></a>==2.1.1 Kafka的优点有那些？==</h4><ul>
<li><strong>高吞吐量</strong>：我们在Kafka中不需要任何大型硬件，因为它能够处理高速和大容量数据。此外，它还可以支持每秒数千条消息的消息吞吐量。</li>
<li><strong>低延迟</strong>：Kafka可以轻松处理这些消息，具有毫秒级的极低延迟，这是大多数新用例所要求的。</li>
<li><strong>容错</strong>：Kafka能够抵抗集群中的节点/机器故障。</li>
<li><strong>持久性</strong>：由于Kafka支持消息复制，因此消息永远不会丢失。这是持久性背后的原因之一。</li>
<li><strong>可扩展性</strong>：Kafka可以扩展，而不需要通过添加额外的节点而在运行中造成任何停机。</li>
</ul>
<h4 id="2-1-2-Kafka的缺点有哪些？"><a href="#2-1-2-Kafka的缺点有哪些？" class="headerlink" title="2.1.2 Kafka的缺点有哪些？"></a>2.1.2 Kafka的缺点有哪些？</h4><ul>
<li>由于是批量发送，数据并非真正的实时；</li>
<li>对于mqtt协议不支持；</li>
<li>不支持物联网传感数据直接接入；</li>
<li>仅支持统一分区内消息有序，无法实现全局消息有序；</li>
<li>监控不完善，需要安装插件；</li>
<li>依赖zookeeper进行元数据管理；</li>
</ul>
<h4 id="2-2-为什么要使用-Kafka？为什么要使用消息队列？"><a href="#2-2-为什么要使用-Kafka？为什么要使用消息队列？" class="headerlink" title="2.2 为什么要使用 Kafka？为什么要使用消息队列？"></a>2.2 为什么要使用 Kafka？为什么要使用消息队列？</h4><p><strong>解耦，削峰，异步和</strong></p>
<ul>
<li><strong>冗余</strong>：<br>可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。</li>
<li><strong>健壮性</strong>：<br>消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。</li>
</ul>
<h4 id="3-Kafka中有哪几个组件"><a href="#3-Kafka中有哪几个组件" class="headerlink" title="3. Kafka中有哪几个组件?"></a>3. Kafka中有哪几个组件?</h4><p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwtzu76u8dj31hn0u0jy1.jpg" alt="image-20211127204436299"></p>
<p><strong>主题(Topic)</strong>：Kafka主题是一堆或一组消息。<br><strong>生产者(Producer)</strong>：在Kafka，生产者发布通信以及向Kafka主题发布消息。<br><strong>消费者(Consumer)</strong>：Kafka消费者订阅了一个主题，并且还从主题中读取和处理消息。<br><strong>经纪人(Brokers)</strong>：在管理主题中的消息存储时，我们使用Kafka Brokers</p>
<h4 id="3-1-什么是消费者组？"><a href="#3-1-什么是消费者组？" class="headerlink" title="3.1 什么是消费者组？"></a>3.1 什么是消费者组？</h4><p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwuv90p0frj314j0u0wih.jpg" alt="image-20211128145127151"></p>
<p>消费者组的概念是Apache Kafka独有的。基本上，每个Kafka消费群体都由一个或多个共同消费一组订阅主题的消费者组成。</p>
<p>详见 <strong>25. Consumer Group 是什么概念？</strong></p>
<h4 id="3-2-Leader和Follower的概念是什么？"><a href="#3-2-Leader和Follower的概念是什么？" class="headerlink" title="3.2 Leader和Follower的概念是什么？"></a>3.2 Leader和Follower的概念是什么？</h4><p>在Kafka的每个分区中，都有一个服务器充当leader，0到多个服务器充当follower的角色。</p>
<h4 id="3-3-Kafka-Follower如何与Leader同步数据"><a href="#3-3-Kafka-Follower如何与Leader同步数据" class="headerlink" title="3.3 Kafka Follower如何与Leader同步数据?"></a>3.3 Kafka Follower如何与Leader同步数据?</h4><p>Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求 All Alive Follower 都复制完，这条消息才会被认为 commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower 异步的从 Leader 复制数据，数据只要被 Leader 写入 log 就被认为已经 commit，这种情况下，如果 leader 挂掉，会丢失数据，kafka 使用 ISR 的方式很好的均衡了确保数据不丢失以及吞吐率。Follower 可以批量的从 Leader 复制数据，而且 Leader 充分利用磁盘顺序读以及 send file(zero copy) 机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了 Follower 与 Leader 的消息量差。</p>
<h4 id="4-数据传输的事物定义有哪三种"><a href="#4-数据传输的事物定义有哪三种" class="headerlink" title="4. 数据传输的事物定义有哪三种?"></a>4. 数据传输的事物定义有哪三种?</h4><p>数据传输的事务定义通常有以下三种级别:<br>(1)最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输<br>(2)最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.<br>(3)精确的一次(Exactly once): 不会漏传输也不会重复传输,每个消息都传输被一次而 且仅仅被传输一次，这是大家所期望的</p>
<h4 id="5-Kafka-判断一个节点是否还活着有那两个条件"><a href="#5-Kafka-判断一个节点是否还活着有那两个条件" class="headerlink" title="==5. Kafka 判断一个节点是否还活着有那两个条件?=="></a>==5. Kafka 判断一个节点是否还活着有那两个条件?==</h4><p>(1)节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接<br>(2)如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久</p>
<h4 id="5-1-Kafka中的-zookeeper-起到什么作用？可以不用zookeeper吗？"><a href="#5-1-Kafka中的-zookeeper-起到什么作用？可以不用zookeeper吗？" class="headerlink" title="==5.1 Kafka中的 zookeeper 起到什么作用？可以不用zookeeper吗？=="></a>==5.1 Kafka中的 zookeeper 起到什么作用？可以不用zookeeper吗？==</h4><p>zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group 的管理以及 offset 的值。考虑到 zookeeper 本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了 zookeeper 的作用。新的 consumer 使用了 kafka 内部的 group coordination 协议，也减少了对 zookeeper 的依赖，</p>
<p>但是 broker 依然依赖于 zookeeper，zookeeper 在kafka中还用来选举 controller 和检测 broker 是否存活等等。</p>
<h4 id="6-producer-是否直接将数据发送到-broker-的-leader-主节点"><a href="#6-producer-是否直接将数据发送到-broker-的-leader-主节点" class="headerlink" title="6. producer 是否直接将数据发送到 broker 的 leader(主节点)?"></a>6. producer 是否直接将数据发送到 broker 的 leader(主节点)?</h4><p>是的。producer 直接将数据发送到 broker 的 leader(主节点)，不需要在多个节点进行分发，为了 帮助 producer 做到这点，所有的 Kafka 节点都可以及时的告知:哪些节点是活动的，目标 topic 目标分区的 leader 在哪。这样 producer 就可以直接将消息发送到目的地了</p>
<h4 id="7-Kafa-consumer-是否可以消费指定分区消息"><a href="#7-Kafa-consumer-是否可以消费指定分区消息" class="headerlink" title="7. Kafa consumer 是否可以消费指定分区消息?"></a>7. Kafa consumer 是否可以消费指定分区消息?</h4><p>Kafa consumer 消费消息时，向broker发出”fetch”请求去消费特定分区的消息，consumer指定消息在日志中的偏移量(offset)，就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的</p>
<h4 id="7-1-Kafka-分区的目的？"><a href="#7-1-Kafka-分区的目的？" class="headerlink" title="7.1 Kafka 分区的目的？"></a>7.1 Kafka 分区的目的？</h4><p>分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。</p>
<h4 id="8-Kafka-消息是采用-Pull-模式，还是-Push-模式"><a href="#8-Kafka-消息是采用-Pull-模式，还是-Push-模式" class="headerlink" title="==8. Kafka 消息是采用 Pull 模式，还是 Push 模式?=="></a>==8. Kafka 消息是采用 Pull 模式，还是 Push 模式?==</h4><p><strong>Kafka 还是选取了传统的pull模式。</strong></p>
<p>Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统的设计:<strong>producer 将消息推送到 broker，consumer 从 broker 拉取消息</strong>。</p>
<p>一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下游的 consumer。这样做有好处也有坏处:由 broker 决定消息推送的速率，对于不同消费速率的 consumer 就不太好处理了。消息系统都致力于让 consumer 以最大的速率最快速的消费消息，但不幸的是，<strong>push 模式下，当 broker 推送的速率远大于 consumer 消费的速率时， consumer 恐怕就要崩溃了</strong>。最终 Kafka 还是选取了传统的 pull 模式。</p>
<p><strong>Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数据</strong>。Push 模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免 consumer 崩溃而采用较低的推送速率，将可能导致一 次只推送较少的消息而造成浪费。Pull 模式下，consumer 就可以根据自己的消费能力去决定这些策略</p>
<p><strong>Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询， 直到新消息到达</strong>。为了避免这点，Kafka 有个参数可以让 consumer 阻塞直到新消息到达 (当然也可以阻塞直到消息的数量达到某个特定的量这样就可以批量发送）。</p>
<h4 id="9-Kafka-存储在硬盘上的消息格式是什么"><a href="#9-Kafka-存储在硬盘上的消息格式是什么" class="headerlink" title="==9. Kafka 存储在硬盘上的消息格式是什么?=="></a>==9. <strong>Kafka 存储在硬盘上的消息格式是什么?</strong>==</h4><p>消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和 CRC32 校验码。</p>
<ul>
<li>消息长度: 4 bytes (value: 1+4+n)</li>
<li>版本号: 1 byte</li>
<li>CRC 校验码: 4 bytes</li>
<li>具体的消息: n bytes</li>
</ul>
<h4 id="9-1-Kafka可以接收的消息最大为多少？"><a href="#9-1-Kafka可以接收的消息最大为多少？" class="headerlink" title="9.1 Kafka可以接收的消息最大为多少？"></a>9.1 Kafka可以接收的消息最大为多少？</h4><p>Kafka可以接收的最大消息大小约为1000000字节。</p>
<h4 id="10-Kafka-高效文件存储设计特点"><a href="#10-Kafka-高效文件存储设计特点" class="headerlink" title="10. Kafka 高效文件存储设计特点:"></a>10. Kafka 高效文件存储设计特点:</h4><p>(1).Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。<br>(2).通过索引信息可以快速定位 message 和确定 response 的最大大小。<br>(3).通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。<br>(4).通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小</p>
<h4 id="11-Kafka-与传统消息系统之间有三个关键区别"><a href="#11-Kafka-与传统消息系统之间有三个关键区别" class="headerlink" title="11. Kafka 与传统消息系统之间有三个关键区别"></a>11. Kafka 与传统消息系统之间有三个关键区别</h4><p>(1).Kafka <strong>持久化日志</strong>，这些日志可以被重复读取和无限期保留<br>(2).Kafka 是一个<strong>分布式系统:</strong>它以集群的方式运行，可以<strong>灵活伸缩</strong>，在内部通过复制数据<strong>提升容错能力和高可用性</strong><br>(3).Kafka <strong>支持实时的流式处理</strong></p>
<h4 id="12-Kafka-创建-Topic-时如何将分区放置到不同的-Broker-中"><a href="#12-Kafka-创建-Topic-时如何将分区放置到不同的-Broker-中" class="headerlink" title="12. Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中"></a>12. Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中</h4><ul>
<li>副本因子不能大于 Broker 的个数;</li>
<li>第一个分区(编号为 0)的第一个副本放置位置是随机从 brokerList 选择的; </li>
<li>其他分区的第一个副本放置位置相对于第 0 个分区依次往后移。也就是如果我们有 5 个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五 个 Broker 上;第三个分区将会放在第一个 Broker 上;第四个分区将会放在第二个 Broker 上，依次类推;</li>
<li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的</li>
</ul>
<h4 id="13-Kafka-新建的分区会在哪个目录下创建"><a href="#13-Kafka-新建的分区会在哪个目录下创建" class="headerlink" title="13. Kafka 新建的分区会在哪个目录下创建"></a>13. Kafka 新建的分区会在哪个目录下创建</h4><p>在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘 上用于提高读写性能。当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个 目录下创建文件夹用于存放数据。</p>
<p>但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢? </p>
<p>答案是:<strong>Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，</strong>分区目录名为 Topic 名+分区 ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录!也就 是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。</p>
<h4 id="14-partition-的数据如何保存到硬盘"><a href="#14-partition-的数据如何保存到硬盘" class="headerlink" title="14. partition 的数据如何保存到硬盘"></a>14. partition 的数据如何保存到硬盘</h4><ol>
<li>topic 中的多个 partition 以文件夹的形式保存到 broker，每个分区序号从 0 递增， 且消息有序</li>
<li>Partition 文件下有多个 segment(xxx.index，xxx.log)</li>
<li>segment 文件里的大小和配置文件大小一致可以根据要求修改默认为 1g</li>
<li>如果大小大于 1g 时，会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移量命名</li>
</ol>
<h4 id="15-kafka-的-ack-机制"><a href="#15-kafka-的-ack-机制" class="headerlink" title="==15. kafka 的 ack 机制=="></a>==15. kafka 的 ack 机制==</h4><p><strong>request.required.acks 有三个值 0，1， -1</strong>。</p>
<p>0: 生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候 就会丢数据</p>
<p>1: 服务端会等待 ack 值leader副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他不确保是否复制完成新 leader 也会导致数据丢失</p>
<p>-1: 同样在1的基础上服务端会等所有的 follower 的Replica受到数据后才会收到 leader 发出 的 ack，这样数据不会丢失</p>
<h4 id="16-Kafka-的消费者如何消费数据"><a href="#16-Kafka-的消费者如何消费数据" class="headerlink" title="16. Kafka 的消费者如何消费数据"></a>16. Kafka 的消费者如何消费数据</h4><p>消费者每次消费数据的时候，消费者都会记录消费的物理偏移量(offset)的位置，等到下次消费时，他会接着上次位置继续消费。</p>
<h4 id="16-1-偏移的作用是什么？"><a href="#16-1-偏移的作用是什么？" class="headerlink" title="16.1 偏移的作用是什么？"></a>16.1 偏移的作用是什么？</h4><p>给分区中的消息提供了一个顺序ID号，我们称之为偏移量。因此，为了唯一地识别分区中的每条消息，我们使用这些偏移量。</p>
<h4 id="17-消费者负载均衡策略"><a href="#17-消费者负载均衡策略" class="headerlink" title="17. 消费者负载均衡策略"></a>17. 消费者负载均衡策略</h4><p>一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如果组中成员太多会有空闲的成员。</p>
<h4 id="18-数据有序"><a href="#18-数据有序" class="headerlink" title="18. 数据有序"></a>18. 数据有序</h4><p>一个消费者组里它的内部是有序的 </p>
<p>消费者组与消费者组之间是无序的</p>
<h4 id="19-kafaka-生产数据时数据的分组策略"><a href="#19-kafaka-生产数据时数据的分组策略" class="headerlink" title="19.kafaka 生产数据时数据的分组策略"></a>19.kafaka 生产数据时数据的分组策略</h4><ul>
<li>生产者决定数据产生到集群的哪个 partition 中</li>
<li>每一条消息都是以(key，value)格式</li>
<li>Key 是由生产者发送数据传入</li>
<li>所以生产者(key)决定了数据产生到集群的哪个 partition</li>
</ul>
<h4 id="20-Kafka系统工具有哪些类型？"><a href="#20-Kafka系统工具有哪些类型？" class="headerlink" title="20. Kafka系统工具有哪些类型？"></a>20. Kafka系统工具有哪些类型？</h4><ol>
<li><strong>Kafka迁移工具</strong>：它有助于将代理从一个版本迁移到另一个版本。</li>
<li><strong>Mirror Maker</strong>：Mirror Maker工具有助于将一个Kafka集群的镜像提供给另一个。</li>
<li><strong>消费者检查</strong>:对于指定的主题集和消费者组，它显示主题，分区，所有者。</li>
</ol>
<h4 id="20-1-监控-Kafka-的框架都有哪些"><a href="#20-1-监控-Kafka-的框架都有哪些" class="headerlink" title="20.1 监控 Kafka 的框架都有哪些?"></a>20.1 监控 Kafka 的框架都有哪些?</h4><ol>
<li><strong>Kafka Manager</strong>:应该算是最有名的专属 Kafka 监控框架了，是独立的监控系统。</li>
<li><strong>Kafka Monitor</strong>:LinkedIn 开源的免费框架，支持对集群进行系统测试，并实时监控测试结果。</li>
<li><strong>CruiseControl</strong>:也是 LinkedIn 公司开源的监控框架，用于实时监测资源使用率，以及 提供常用运维操作等。无 UI 界面，只提供REST API。</li>
<li><strong>JMX 监控</strong>:由于 Kafka 提供的监控指标都是基于 JMX 的，因此，市面上任何能够集成 JMX 的框架都可以使用，比如 Zabbix 和 Prometheus。</li>
<li><strong>已有大数据平台自己的监控体系</strong>:像 Cloudera 提供的 CDH 这类大数据平台，天然就提 供 Kafka 监控方案。</li>
<li><strong>JMXTool</strong>:社区提供的命令行工具，能够实时监控 JMX 指标。答上这一条，属于绝对 的加分项，因为知道的人很少，而且会给人一种你对 Kafka 工具非常熟悉的感觉。如果 你暂时不了解它的用法，可以在命令行以无参数方式执行一下kafka-run-class.sh kafka.tools.JmxTool，学习下它的用法。</li>
</ol>
<h4 id="21-Kafka-是如何实现高吞吐率的？"><a href="#21-Kafka-是如何实现高吞吐率的？" class="headerlink" title="==21 Kafka 是如何实现高吞吐率的？=="></a>==21 Kafka 是如何实现高吞吐率的？==</h4><p>Kafka是分布式消息系统，需要处理海量的消息，Kafka的设计是把所有的消息都写入速度低容量大的硬盘，以此来换取更强的存储能力，但实际上，使用硬盘并没有带来过多的性能损失。kafka主要使用了以下几个方式实现了超高的吞吐率：</p>
<ul>
<li><strong>顺序读写</strong>；由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。</li>
<li><strong>零拷贝</strong>: 减少拷贝次数</li>
<li><strong>批量发送</strong>: Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。</li>
<li><strong>Pull 拉模式</strong>:使用拉模式进行消息的获取消费，与消费端处理能力相符。</li>
<li><strong>缓存</strong>: Cache Filesystem Cache PageCache缓存</li>
<li><strong>文件分段。</strong></li>
<li><strong>数据压缩。</strong></li>
</ul>
<blockquote>
<p>零拷贝</p>
<p>先来看看非零拷贝的情况：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwuvcfvylyj31ea0u0mzl.jpg" alt="image-20211128145445145"></p>
<p>可以看到数据的拷贝从内存拷贝到 Kafka 服务进程那块，又拷贝到 Socket 缓存那块，整个过程耗费的时间比较高。</p>
<p>Kafka 利用了 Linux 的 sendFile 技术（NIO），省去了进程切换和一次数据拷贝，让性能变得更好。</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gwuvczksbwj31fe0u0di3.jpg" alt="image-20211128145516465"></p>
</blockquote>
<h4 id="22-Kafka中的-ISR、AR-又代表什么？ISR-的伸缩又指什么？"><a href="#22-Kafka中的-ISR、AR-又代表什么？ISR-的伸缩又指什么？" class="headerlink" title="22. Kafka中的 ISR、AR 又代表什么？ISR 的伸缩又指什么？"></a>22. Kafka中的 ISR、AR 又代表什么？ISR 的伸缩又指什么？</h4><p>ISR：In-Sync Replicas 副本同步队列；</p>
<p>ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p>
<p>AR：Assigned Replicas 所有副本；</p>
<h4 id="22-1-什么情况下一个-Broker-会从ISR中踢出去"><a href="#22-1-什么情况下一个-Broker-会从ISR中踢出去" class="headerlink" title="22.1 什么情况下一个 Broker 会从ISR中踢出去?"></a>22.1 什么情况下一个 Broker 会从ISR中踢出去?</h4><p>leader 会维护一个与其基本保持同步的 Replica 列表，该列表称为 ISR(in-sync Replica)，每个 Partition 都会有一个 ISR，而且是由 leader 动态维护 ，如果一个 follower 比一个 leader 落后太多，或者超过一定时间未发起数据复制请求，则 leader 将其重 ISR 中移除 。</p>
<h4 id="22-2-如果-Leader-Crash-时，ISR为空怎么办"><a href="#22-2-如果-Leader-Crash-时，ISR为空怎么办" class="headerlink" title="22.2 如果 Leader Crash 时，ISR为空怎么办"></a>22.2 如果 Leader Crash 时，ISR为空怎么办</h4><p>kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：</p>
<p>true（默认）：<br>允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。<br>false：<br>不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。</p>
<h4 id="22-3-副本长时间不在ISR中，这意味着什么？"><a href="#22-3-副本长时间不在ISR中，这意味着什么？" class="headerlink" title="22.3 副本长时间不在ISR中，这意味着什么？"></a>22.3 副本长时间不在ISR中，这意味着什么？</h4><p>意味着 follower 不能像 leader 收集数据那样快速地获取数据。</p>
<h4 id="23-Kafka-Producer如何优化写入速度"><a href="#23-Kafka-Producer如何优化写入速度" class="headerlink" title="23. Kafka Producer如何优化写入速度?"></a>23. Kafka Producer如何优化写入速度?</h4><ul>
<li>增加线程</li>
<li>提高 batch.size</li>
<li>增加更多 producer 实例</li>
<li>增加 partition 数</li>
<li>设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；</li>
<li>跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置。</li>
</ul>
<h4 id="24-Kafka-Unclean-配置代表什么？会对-spark-streaming-消费有什么影响？"><a href="#24-Kafka-Unclean-配置代表什么？会对-spark-streaming-消费有什么影响？" class="headerlink" title="24. Kafka Unclean 配置代表什么？会对 spark streaming 消费有什么影响？"></a>24. Kafka Unclean 配置代表什么？会对 spark streaming 消费有什么影响？</h4><p>unclean.leader.election.enable 为 true 的话，意味着非 ISR 集合的 broker 也可以参与选举，这样有可能就会丢数据，spark streaming在消费过程中拿到的 end offset 会突然变小，导致 spark streaming job 挂掉。如果 unclean.leader.election.enable 参数设置为 true，就有可能发生数据丢失和数据不一致的情况，Kafka 的可靠性就会降低；而如果 unclean.leader.election.enable 参数设置为 false，Kafka 的可用性就会降低。</p>
<h4 id="25-Kafka-中-Consumer-Group-是什么概念？"><a href="#25-Kafka-中-Consumer-Group-是什么概念？" class="headerlink" title="==25. Kafka 中 Consumer Group 是什么概念？=="></a>==25. Kafka 中 Consumer Group 是什么概念？==</h4><p>同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。</p>
<h4 id="26-Kafka-中的消息是否会丢失和重复消费？"><a href="#26-Kafka-中的消息是否会丢失和重复消费？" class="headerlink" title="==26. Kafka 中的消息是否会丢失和重复消费？=="></a>==26. Kafka 中的消息是否会丢失和重复消费？==</h4><p>要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。</p>
<ul>
<li><p>消息发送：Kafka消息发送有两种方式：<strong>同步</strong>（sync）和<strong>异步</strong>（async），默认是同步方式，可通过producer.type属性进行配置。</p>
<p>见“15. Kafka的ack机制”</p>
</li>
<li><p>消息消费：Kafka消息消费有两个consumer接口，Low-level API和High-level API：</p>
<blockquote>
<p>Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；</p>
<p>High-level API：封装了对parition和offset的管理，使用简单；<br>如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；</p>
</blockquote>
</li>
<li><p>解决办法：</p>
<ul>
<li>针对消息丢失：<br>同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；<br>异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；<ul>
<li>针对消息重复：<br>将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="27-为什么Kafka不支持读写分离？"><a href="#27-为什么Kafka不支持读写分离？" class="headerlink" title="==27. 为什么Kafka不支持读写分离？=="></a>==27. 为什么Kafka不支持读写分离？==</h4><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从而实现的是一种主写主读的生产消费模型。</p>
<p>Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:</p>
<p><strong>数据一致性问题。</strong>数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。<br><strong>延时问题</strong>。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</p>
<h4 id="28-Kafka-中是怎么体现消息顺序性的？"><a href="#28-Kafka-中是怎么体现消息顺序性的？" class="headerlink" title="28. Kafka 中是怎么体现消息顺序性的？"></a>28. Kafka 中是怎么体现消息顺序性的？</h4><p>kafka 每个 partition 中的消息在写入时都是有序的，消费时，每个 partition 只能被每一个 group 中的一个消费者消费，保证了消费时也是有序的。<br>整个 topic 不保证有序。如果为了保证 topic 整个有序，那么将 partition 调整为1.</p>
<h4 id="29-Kafka-如何实现延迟队列"><a href="#29-Kafka-如何实现延迟队列" class="headerlink" title="29. Kafka 如何实现延迟队列?"></a>29. Kafka 如何实现延迟队列?</h4><p>Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是<strong>基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）</strong></p>
<p><strong>Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务</strong>。</p>
<h4 id="30-Kafka中的HW、LEO、LSO、LW等分别代表什么？"><a href="#30-Kafka中的HW、LEO、LSO、LW等分别代表什么？" class="headerlink" title="30. Kafka中的HW、LEO、LSO、LW等分别代表什么？"></a><strong>30. Kafka中的HW、LEO、LSO、LW等分别代表什么？</strong></h4><p>HW:High Watermark 高水位，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置上一条信息。<br>LEO:LogEndOffset 当前日志文件中下一条待写信息的offset<br>HW/LEO这两个都是指最后一条的下一条的位置而不是指最后一条的位置。<br>LSO:Last Stable Offset 对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同。<br>LW:Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值</p>
<h4 id="31-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"><a href="#31-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？" class="headerlink" title="31. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"></a><strong>31. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</strong></h4><p>不正确，通过自定义分区分配策略，可以将一个consumer指定消费所有partition。</p>
<h4 id="32-优先副本是什么？它有什么特殊的作用？"><a href="#32-优先副本是什么？它有什么特殊的作用？" class="headerlink" title="32. 优先副本是什么？它有什么特殊的作用？"></a><strong>32. 优先副本是什么？它有什么特殊的作用？</strong></h4><p>优先副本 会是默认的leader副本 发生leader变化时重选举会优先选择优先副本作为leader</p>
<h4 id="33-如果我指定了一个offset，Kafka怎么查找到对应的消息？"><a href="#33-如果我指定了一个offset，Kafka怎么查找到对应的消息？" class="headerlink" title="33.如果我指定了一个offset，Kafka怎么查找到对应的消息？"></a>33.<strong>如果我指定了一个offset，Kafka怎么查找到对应的消息？</strong></h4><p>1.通过文件名前缀数字x找到该绝对offset 对应消息所在文件<br>2.offset-x为在文件中的相对偏移<br>3.通过index文件中记录的索引找到最近的消息的位置<br>4.从最近位置开始逐条寻找</p>
<h4 id="34-谈一谈-Kafka-的再均衡"><a href="#34-谈一谈-Kafka-的再均衡" class="headerlink" title="34. 谈一谈 Kafka 的再均衡"></a>34. 谈一谈 Kafka 的再均衡</h4><p>在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：</p>
<p>第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。<br>第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。<br>所以对于Rebalance来说，Coordinator起着至关重要的作用</p>
<h4 id="35-如何调优-Kafka"><a href="#35-如何调优-Kafka" class="headerlink" title="==35. 如何调优 Kafka?=="></a>==35. 如何调优 Kafka?==</h4><ul>
<li><strong>Producer 端</strong>:增加 batch.size、linger.ms，启用压缩，关闭重试等。</li>
<li><strong>Broker 端</strong>:增加 num.replica.fetchers，提升 Follower 同步 TPS，避免 Broker Full GC 等。</li>
<li><strong>Consumer</strong>:增加 fetch.min.bytes 等。</li>
</ul>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Shang Liang Liang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka/">http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Shang Liang Liang's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Kafka/">Kafka</a></div><div class="post_share"><div class="social-share" data-image="https://imgchr.com/i/YI6RDH" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2021/11/29/%E9%A1%B9%E7%9B%AE%E8%B8%A9%E5%9D%91/%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0/"><img class="prev_cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gwvtexsqevj30go08r0sw.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">开窗函数</div></div></a></div><div class="next-post pull_right"><a href="/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%92%8C%E4%B8%80%E8%87%B4%E6%80%A7/"><img class="next_cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gwvtnero3ij31hn0u00ts.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Kafka数据可靠性和一致性</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/11/18/Java面试/Kafka数据可靠性和一致性/" title="Kafka数据可靠性和一致性"><img class="relatedPosts_cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gwvtnero3ij31hn0u00ts.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-11-18</div><div class="relatedPosts_title">Kafka数据可靠性和一致性</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script>var disqus_config = function () {
  this.page.url = 'http://yoursite.com/2021/11/18/Java%E9%9D%A2%E8%AF%95/Kafka/';
  this.page.identifier = '2021/11/18/Java面试/Kafka/';
  this.page.title = 'Kafka';
};
(function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://jackshang.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Shang Liang Liang</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="/js/third-party/ClickShowText.js"></script><script src="/js/search/local-search.js"></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script></body></html>